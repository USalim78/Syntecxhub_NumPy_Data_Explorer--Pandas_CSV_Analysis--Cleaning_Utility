{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# numpy_data_explorer.py\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "print(\"NumPy Data Explorer - Syntecxhub Internship Week 1 \\n\")\n",
        "\n",
        "# 1. Array creation\n",
        "arr_1d = np.arange(1, 11)\n",
        "arr_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "arr_random = np.random.randint(0, 100, size=(5, 5))\n",
        "zeros = np.zeros((3, 4))\n",
        "ones = np.ones((4, 3))\n",
        "linspace_arr = np.linspace(0, 1, 11)\n",
        "\n",
        "print(\"1. Array Creation Examples:\")\n",
        "print(\"1D array:\", arr_1d)\n",
        "print(\"2D array:\\n\", arr_2d)\n",
        "print(\"Random 5x5:\\n\", arr_random)\n",
        "print(\"Zeros (3x4):\\n\", zeros)\n",
        "print(\"Ones (4x3):\\n\", ones)\n",
        "print(\"Linspace:\", linspace_arr)\n",
        "\n",
        "# 2. Indexing & Slicing\n",
        "print(\"\\n2. Indexing & Slicing:\")\n",
        "print(\"arr_2d[1, 2] =\", arr_2d[1, 2])\n",
        "print(\"First row:\", arr_2d[0])\n",
        "print(\"Last column:\", arr_2d[:, -1])\n",
        "print(\"Subarray (rows 0-1, cols 1-2):\\n\", arr_2d[0:2, 1:3])\n",
        "\n",
        "# 3. Mathematical & Statistical Operations\n",
        "print(\"\\n3. Mathematical & Statistical Operations:\")\n",
        "print(\"Mean of arr_random:\", np.mean(arr_random))\n",
        "print(\"Std deviation:\", np.std(arr_random))\n",
        "print(\"Sum axis=0:\", np.sum(arr_random, axis=0))\n",
        "print(\"Max per row:\", np.max(arr_random, axis=1))\n",
        "print(\"Element-wise sqrt:\\n\", np.sqrt(arr_random.astype(float)))\n",
        "\n",
        "# 4. Reshaping & Broadcasting\n",
        "print(\"\\n4. Reshaping & Broadcasting:\")\n",
        "# A common and flexible alternative for converting to 1D\n",
        "flat = arr_random.reshape(25)           # or arr_random.flatten() / .ravel()\n",
        "print(\"\\n→ Reshaped to 1D (25,):\")\n",
        "print(flat)     #this will reshape the 5x5 array in to 1 1d array of 25 .\n",
        "\n",
        "reshaped_2 = flat.reshape(5, 5)\n",
        "print(reshaped_2)    #This will reshape back from 1d to 5x5.\n",
        "row_vector = np.array([[10, 20, 30, 40, 50]])\n",
        "broadcast_add = reshaped_2 + row_vector           # Broadcasting\n",
        "broadcast_mult = reshaped_2 * 2\n",
        "print(\"After broadcasting add (first row + [10,20,30,40,50]):\\n\", broadcast_add)\n",
        "\n",
        "# 5. Save / Load\n",
        "np.save('my_array.npy', arr_random)\n",
        "loaded = np.load('my_array.npy')\n",
        "print(\"\\n5. Save/Load: Loaded array matches original?\", np.array_equal(arr_random, loaded))\n",
        "\n",
        "# 6. Performance comparison with Python lists\n",
        "size = 10_000_000\n",
        "py_list = list(range(size))\n",
        "np_arr = np.arange(size)\n",
        "\n",
        "start = time.time()\n",
        "sum_py = sum(py_list)\n",
        "end = time.time()\n",
        "print(f\"\\nPython list sum: {end-start:.4f} sec\")\n",
        "\n",
        "start = time.time()\n",
        "sum_np = np_arr.sum()\n",
        "end = time.time()\n",
        "print(f\"NumPy sum: {end-start:.4f} sec\")\n",
        "print(f\"NumPy is ~{sum_py/sum_np:.0f}x faster in this case!\")\n",
        "\n",
        "print(\"\\n=== NumPy Data Explorer Completed ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhOtiUV9wEBQ",
        "outputId": "2e50711a-68c1-4c09-b6b0-827d20d4d6c3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy Data Explorer - Syntecxhub Internship Week 1 \n",
            "\n",
            "1. Array Creation Examples:\n",
            "1D array: [ 1  2  3  4  5  6  7  8  9 10]\n",
            "2D array:\n",
            " [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "Random 5x5:\n",
            " [[93 71 14 87 32]\n",
            " [86 12 48 51 38]\n",
            " [87 92 17 58 88]\n",
            " [77 88 56 24 60]\n",
            " [65 95 50 82 55]]\n",
            "Zeros (3x4):\n",
            " [[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "Ones (4x3):\n",
            " [[1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]\n",
            " [1. 1. 1.]]\n",
            "Linspace: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "2. Indexing & Slicing:\n",
            "arr_2d[1, 2] = 6\n",
            "First row: [1 2 3]\n",
            "Last column: [3 6 9]\n",
            "Subarray (rows 0-1, cols 1-2):\n",
            " [[2 3]\n",
            " [5 6]]\n",
            "\n",
            "3. Mathematical & Statistical Operations:\n",
            "Mean of arr_random: 61.04\n",
            "Std deviation: 26.180114591040276\n",
            "Sum axis=0: [408 358 185 302 273]\n",
            "Max per row: [93 86 92 88 95]\n",
            "Element-wise sqrt:\n",
            " [[9.64365076 8.42614977 3.74165739 9.32737905 5.65685425]\n",
            " [9.2736185  3.46410162 6.92820323 7.14142843 6.164414  ]\n",
            " [9.32737905 9.59166305 4.12310563 7.61577311 9.38083152]\n",
            " [8.77496439 9.38083152 7.48331477 4.89897949 7.74596669]\n",
            " [8.06225775 9.74679434 7.07106781 9.05538514 7.41619849]]\n",
            "\n",
            "4. Reshaping & Broadcasting:\n",
            "\n",
            "→ Reshaped to 1D (25,):\n",
            "[93 71 14 87 32 86 12 48 51 38 87 92 17 58 88 77 88 56 24 60 65 95 50 82\n",
            " 55]\n",
            "[[93 71 14 87 32]\n",
            " [86 12 48 51 38]\n",
            " [87 92 17 58 88]\n",
            " [77 88 56 24 60]\n",
            " [65 95 50 82 55]]\n",
            "After broadcasting add (first row + [10,20,30,40,50]):\n",
            " [[103  91  44 127  82]\n",
            " [ 96  32  78  91  88]\n",
            " [ 97 112  47  98 138]\n",
            " [ 87 108  86  64 110]\n",
            " [ 75 115  80 122 105]]\n",
            "\n",
            "5. Save/Load: Loaded array matches original? True\n",
            "\n",
            "Python list sum: 0.0914 sec\n",
            "NumPy sum: 0.0075 sec\n",
            "NumPy is ~1x faster in this case!\n",
            "\n",
            "=== NumPy Data Explorer Completed ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEBHQuX9vz9n",
        "outputId": "b42e5a31-7c86-4a3f-ac41-bf2d700fc74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas CSV Reader & Basic Analysis - Syntecxhub Week 1 \n",
            "\n",
            "Dataset shape: (891, 12)\n",
            "First 5 rows:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Last 5 rows:\n",
            "     PassengerId  Survived  Pclass                                      Name  \\\n",
            "886          887         0       2                     Montvila, Rev. Juozas   \n",
            "887          888         1       1              Graham, Miss. Margaret Edith   \n",
            "888          889         0       3  Johnston, Miss. Catherine Helen \"Carrie\"   \n",
            "889          890         1       1                     Behr, Mr. Karl Howell   \n",
            "890          891         0       3                       Dooley, Mr. Patrick   \n",
            "\n",
            "        Sex   Age  SibSp  Parch      Ticket   Fare Cabin Embarked  \n",
            "886    male  27.0      0      0      211536  13.00   NaN        S  \n",
            "887  female  19.0      0      0      112053  30.00   B42        S  \n",
            "888  female   NaN      1      2  W./C. 6607  23.45   NaN        S  \n",
            "889    male  26.0      0      0      111369  30.00  C148        C  \n",
            "890    male  32.0      0      0      370376   7.75   NaN        Q  \n",
            "\n",
            "Data types:\n",
            " PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "Summary Statistics:\n",
            "        PassengerId    Survived      Pclass                 Name   Sex  \\\n",
            "count    891.000000  891.000000  891.000000                  891   891   \n",
            "unique          NaN         NaN         NaN                  891     2   \n",
            "top             NaN         NaN         NaN  Dooley, Mr. Patrick  male   \n",
            "freq            NaN         NaN         NaN                    1   577   \n",
            "mean     446.000000    0.383838    2.308642                  NaN   NaN   \n",
            "std      257.353842    0.486592    0.836071                  NaN   NaN   \n",
            "min        1.000000    0.000000    1.000000                  NaN   NaN   \n",
            "25%      223.500000    0.000000    2.000000                  NaN   NaN   \n",
            "50%      446.000000    0.000000    3.000000                  NaN   NaN   \n",
            "75%      668.500000    1.000000    3.000000                  NaN   NaN   \n",
            "max      891.000000    1.000000    3.000000                  NaN   NaN   \n",
            "\n",
            "               Age       SibSp       Parch  Ticket        Fare Cabin Embarked  \n",
            "count   714.000000  891.000000  891.000000     891  891.000000   204      889  \n",
            "unique         NaN         NaN         NaN     681         NaN   147        3  \n",
            "top            NaN         NaN         NaN  347082         NaN    G6        S  \n",
            "freq           NaN         NaN         NaN       7         NaN     4      644  \n",
            "mean     29.699118    0.523008    0.381594     NaN   32.204208   NaN      NaN  \n",
            "std      14.526497    1.102743    0.806057     NaN   49.693429   NaN      NaN  \n",
            "min       0.420000    0.000000    0.000000     NaN    0.000000   NaN      NaN  \n",
            "25%      20.125000    0.000000    0.000000     NaN    7.910400   NaN      NaN  \n",
            "50%      28.000000    0.000000    0.000000     NaN   14.454200   NaN      NaN  \n",
            "75%      38.000000    1.000000    0.000000     NaN   31.000000   NaN      NaN  \n",
            "max      80.000000    8.000000    6.000000     NaN  512.329200   NaN      NaN  \n",
            "\n",
            "Custom stats:\n",
            "Age mean: 29.69911764705882\n",
            "Age median: 28.0\n",
            "Fare max: 512.3292\n",
            "Survived count:\n",
            " Survived\n",
            "0    549\n",
            "1    342\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Filtering Examples:\n",
            "Number of female passengers: 314\n",
            "Survived in 1st class: 136\n",
            "\n",
            "Selected columns sample:\n",
            "                                                Name   Age     Fare  Survived\n",
            "0                            Braund, Mr. Owen Harris  22.0   7.2500         0\n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0  71.2833         1\n",
            "2                             Heikkinen, Miss. Laina  26.0   7.9250         1\n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0  53.1000         1\n",
            "4                           Allen, Mr. William Henry  35.0   8.0500         0\n",
            "\n",
            "Rows 100-110:\n",
            "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
            "100          101         0       3           Petranec, Miss. Matilda  female   \n",
            "101          102         0       3  Petroff, Mr. Pastcho (\"Pentcho\")    male   \n",
            "102          103         0       1         White, Mr. Richard Frasar    male   \n",
            "103          104         0       3        Johansson, Mr. Gustaf Joel    male   \n",
            "104          105         0       3    Gustafsson, Mr. Anders Vilhelm    male   \n",
            "105          106         0       3             Mionoff, Mr. Stoytcho    male   \n",
            "106          107         1       3  Salkjelsvik, Miss. Anna Kristine  female   \n",
            "107          108         1       3            Moss, Mr. Albert Johan    male   \n",
            "108          109         0       3                   Rekic, Mr. Tido    male   \n",
            "109          110         1       3               Moran, Miss. Bertha  female   \n",
            "110          111         0       1    Porter, Mr. Walter Chamberlain    male   \n",
            "\n",
            "      Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
            "100  28.0      0      0   349245   7.8958   NaN        S  \n",
            "101   NaN      0      0   349215   7.8958   NaN        S  \n",
            "102  21.0      0      1    35281  77.2875   D26        S  \n",
            "103  33.0      0      0     7540   8.6542   NaN        S  \n",
            "104  37.0      2      0  3101276   7.9250   NaN        S  \n",
            "105  28.0      0      0   349207   7.8958   NaN        S  \n",
            "106  21.0      0      0   343120   7.6500   NaN        S  \n",
            "107   NaN      0      0   312991   7.7750   NaN        S  \n",
            "108  38.0      0      0   349249   7.8958   NaN        S  \n",
            "109   NaN      1      0   371110  24.1500   NaN        Q  \n",
            "110  47.0      0      0   110465  52.0000  C110        S  \n",
            "\n",
            "Saved 87 high-fare passengers to CSV & Excel\n",
            "\n",
            "=== Pandas Analysis Completed Successfully ===\n"
          ]
        }
      ],
      "source": [
        "# pandas_csv_analysis.py\n",
        "import pandas as pd\n",
        "\n",
        "# Using a popular public dataset (Titanic)\n",
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Pandas CSV Reader & Basic Analysis - Syntecxhub Week 1 \\n\")\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "# 1. Inspect head/tail/dtypes\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nLast 5 rows:\")\n",
        "print(df.tail())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "\n",
        "# 2. Summary statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe(include='all'))\n",
        "\n",
        "print(\"\\nCustom stats:\")\n",
        "print(\"Age mean:\", df['Age'].mean())\n",
        "print(\"Age median:\", df['Age'].median())\n",
        "print(\"Fare max:\", df['Fare'].max())\n",
        "print(\"Survived count:\\n\", df['Survived'].value_counts())\n",
        "\n",
        "# 3. Filtering, selecting, slicing\n",
        "print(\"\\nFiltering Examples:\")\n",
        "female_passengers = df[df['Sex'] == 'female']\n",
        "print(\"Number of female passengers:\", len(female_passengers))\n",
        "\n",
        "survived_pclass1 = df[(df['Survived'] == 1) & (df['Pclass'] == 1)]\n",
        "print(\"Survived in 1st class:\", len(survived_pclass1))\n",
        "\n",
        "# Selecting columns\n",
        "subset_cols = df[['Name', 'Age', 'Fare', 'Survived']]\n",
        "print(\"\\nSelected columns sample:\")\n",
        "print(subset_cols.head())\n",
        "\n",
        "# Slicing rows 100 to 110\n",
        "print(\"\\nRows 100-110:\")\n",
        "print(df.iloc[100:111])\n",
        "\n",
        "# 4. Save filtered results\n",
        "high_fare = df[df['Fare'] > df['Fare'].quantile(0.9)]\n",
        "high_fare.to_csv('high_fare_passengers.csv', index=False)\n",
        "high_fare.to_excel('high_fare_passengers.xlsx', index=False)\n",
        "print(f\"\\nSaved {len(high_fare)} high-fare passengers to CSV & Excel\")\n",
        "\n",
        "print(\"\\n=== Pandas Analysis Completed Successfully ===\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_cleaning_utility.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Using a messy sample dataset (or you can use any real messy CSV)\n",
        "data = {\n",
        "    'Name': ['  Alice', 'Bob ', 'Charlie', 'David', None, 'Alice'],\n",
        "    'Age': [25, 'thirty', 35, 40, None, 25],\n",
        "    ' Salary ': [50000, 60000, None, 70000, 55000, 50000],\n",
        "    'Join_Date': ['2021-01-15', '2021/02/20', '2021-03-10', 'invalid', '2021-05-01', '2021-01-15'],\n",
        "    'Department': ['HR', 'IT', 'IT', 'Finance', 'HR', 'HR']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"=== Data Cleaning Utility - Syntecxhub Week 1 ===\\n\")\n",
        "print(\"Original Data:\")\n",
        "print(df)\n",
        "print(\"\\nInitial Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Cleaning log\n",
        "log = []\n",
        "\n",
        "# 1. Standardize column names\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
        "log.append(\"Standardized column names\")\n",
        "\n",
        "# 2. Handle missing values\n",
        "df['name'].fillna('Unknown', inplace=True)                                                     #Replaces any NaN (missing) values with the string \"Unknown\".\n",
        "df['age'].fillna(df['age'].median() if df['age'].dtype != 'object' else np.nan, inplace=True)\n",
        "df['salary'].fillna(df['salary'].median(), inplace=True)\n",
        "log.append(f\"Filled missing name with 'Unknown', salary with median\")\n",
        "print(\"This Is the data after handeling missing values : \\n\",df)\n",
        "# 3. Fix incorrect dtypes\n",
        "# Age: convert to numeric\n",
        "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "\n",
        "# Join date: parse dates\n",
        "df['join_date'] = pd.to_datetime(df['join_date'], errors='coerce')\n",
        "log.append(\"Converted age to numeric & parsed join_date\")\n",
        "\n",
        "# 4. Remove duplicates\n",
        "initial_rows = len(df)\n",
        "df.drop_duplicates(inplace=True)\n",
        "log.append(f\"Removed {initial_rows - len(df)} duplicate rows\")\n",
        "\n",
        "# 5. Final cleaned dataset\n",
        "print(\"\\nCleaned Dataset:\")\n",
        "print(df)\n",
        "print(\"\\nFinal Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Save cleaned data\n",
        "df.to_csv('cleaned_dataset.csv', index=False)\n",
        "print(f\"\\nCleaned dataset saved as 'cleaned_dataset.csv' ({len(df)} rows)\")\n",
        "print(\"\\n=== Data Cleaning Utility Completed ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNHOpcreM-Wd",
        "outputId": "7a0d178d-66a1-40df-8552-13c91e02782c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Data Cleaning Utility - Syntecxhub Week 1 ===\n",
            "\n",
            "Original Data:\n",
            "      Name     Age   Salary    Join_Date Department\n",
            "0    Alice      25   50000.0  2021-01-15         HR\n",
            "1     Bob   thirty   60000.0  2021/02/20         IT\n",
            "2  Charlie      35       NaN  2021-03-10         IT\n",
            "3    David      40   70000.0     invalid    Finance\n",
            "4     None    None   55000.0  2021-05-01         HR\n",
            "5    Alice      25   50000.0  2021-01-15         HR\n",
            "\n",
            "Initial Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Name        5 non-null      object \n",
            " 1   Age         5 non-null      object \n",
            " 2    Salary     5 non-null      float64\n",
            " 3   Join_Date   6 non-null      object \n",
            " 4   Department  6 non-null      object \n",
            "dtypes: float64(1), object(4)\n",
            "memory usage: 372.0+ bytes\n",
            "None\n",
            "This Is the data after handeling missing values : \n",
            "       name     age   salary   join_date department\n",
            "0    Alice      25  50000.0  2021-01-15         HR\n",
            "1     Bob   thirty  60000.0  2021/02/20         IT\n",
            "2  Charlie      35  55000.0  2021-03-10         IT\n",
            "3    David      40  70000.0     invalid    Finance\n",
            "4  Unknown     NaN  55000.0  2021-05-01         HR\n",
            "5    Alice      25  50000.0  2021-01-15         HR\n",
            "\n",
            "Cleaned Dataset:\n",
            "      name   age   salary  join_date department\n",
            "0    Alice  25.0  50000.0 2021-01-15         HR\n",
            "1     Bob   30.0  60000.0        NaT         IT\n",
            "2  Charlie  35.0  55000.0 2021-03-10         IT\n",
            "3    David  40.0  70000.0        NaT    Finance\n",
            "4  Unknown  30.0  55000.0 2021-05-01         HR\n",
            "5    Alice  25.0  50000.0 2021-01-15         HR\n",
            "\n",
            "Final Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6 entries, 0 to 5\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype         \n",
            "---  ------      --------------  -----         \n",
            " 0   name        6 non-null      object        \n",
            " 1   age         6 non-null      float64       \n",
            " 2   salary      6 non-null      float64       \n",
            " 3   join_date   4 non-null      datetime64[ns]\n",
            " 4   department  6 non-null      object        \n",
            "dtypes: datetime64[ns](1), float64(2), object(2)\n",
            "memory usage: 372.0+ bytes\n",
            "None\n",
            "\n",
            "Cleaned dataset saved as 'cleaned_dataset.csv' (6 rows)\n",
            "\n",
            "=== Data Cleaning Utility Completed ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-152221838.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['name'].fillna('Unknown', inplace=True)                                                     #Replaces any NaN (missing) values with the string \"Unknown\".\n",
            "/tmp/ipython-input-152221838.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].median() if df['age'].dtype != 'object' else np.nan, inplace=True)\n",
            "/tmp/ipython-input-152221838.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['salary'].fillna(df['salary'].median(), inplace=True)\n",
            "/tmp/ipython-input-152221838.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xByozx3AR-GP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}